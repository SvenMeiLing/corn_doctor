<template>
    <n-layout
            :native-scrollbar="false"
            class="p-[20px]"
            ref="containerRef"
    >
        <n-text tag="div" class="text-2xl">è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½,ä½ å¯ä»¥å…ˆè¯•è¯•è¯•è¯•!ğŸ§</n-text>
        <n-space class="mt-2">
            <n-button @click="flowRecognition" type="primary">å¼€å§‹</n-button>
            <n-button @click="socket.close()" type="error">åœæ­¢</n-button>
        </n-space>

        <hr>
        <div class="w-64 h-48 rounded-md dark:bg-zinc-800 bg-zinc-200 flex items-center justify-center"
        >
            <!--å±•ç¤ºæ‘„åƒå¤´ç”»é¢-->
            <img ref="imgRef" class="rounded-md" v-show="isShow" id="output" width="240" height="180" alt="from camera">
            <!--å ä½ç¬¦-->
            <CameraAction class="w-32" v-show="!isShow"/>

        </div>
        <video ref="videoRef" id="video" class="hidden" width="240" height="180" autoplay></video>
    </n-layout>
</template>

<script setup lang="ts">
import {onMounted, ref} from 'vue'
import {CameraAction} from '@vicons/carbon'

const isShow = ref<Boolean>(false)
const videoRef = ref<HTMLVideoElement | null>(null)
const imgRef = ref<HTMLImageElement | null>(null)
let socket: WebSocket;
let stream: MediaStream;

/*
å¼€å¯wsè¿æ¥
 */
const startWebSocket = () => {
    socket = new WebSocket("ws://127.0.0.1:8000/ws");
    socket.onopen = () => {
        console.log("WebSocket connection established");
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        canvas.width = videoRef.value.width;
        canvas.height = videoRef.value.height;
        const timeId = setInterval(() => {
            // é—´éš”100ms å‘é€ä¸€å¸§æ‘„åƒæœºç”»é¢ç»™åç«¯
            ctx?.drawImage(videoRef.value, 0, 0, canvas.width, canvas.height);
            const frame = canvas.toDataURL('image/jpeg');
            if (socket.readyState === socket.OPEN) {
                socket.send(frame);
            } else if (socket.readyState === socket.CLOSED) {
                // å½“é“¾æ¥å…³é—­,åœæ­¢å‘åç«¯å‘é€å¸§, å¹¶å…³é—­æ‘„åƒå¤´, åŒæ—¶å±è”½ç”»é¢
                clearInterval(timeId)
                if (stream) {
                    // éå†æ‰€æœ‰çš„è½¨é“ï¼Œåœæ­¢æ¯ä¸€ä¸ªè§†é¢‘è½¨é“
                    stream.getTracks().forEach(track => {
                        if (track.kind === 'video') {
                            track.stop();
                        }
                    });
                }
                isShow.value = false
                console.log("è¿æ¥å·²ç»å…³é—­");
            }
        }, 100); // æ¯ 100 æ¯«ç§’å‘é€ä¸€å¸§
    };

    socket.onmessage = (event) => {
        console.log("æ”¶åˆ°äº†å›¾åƒå¸§")
        isShow.value = true
        console.log(imgRef.value)
        imgRef.value.src = event.data;

    };

    socket.onclose = () => {
        console.log("WebSocket connection closed");
    };

    socket.onerror = (error) => {
        console.error("WebSocket error: ", error);
    };
}

/*
è·å–ç”¨æˆ·æ‘„åƒå¤´è§†é¢‘æµ
 */
const getMediaStream = async () => {
    // è·å–æ‘„åƒå¤´è§†é¢‘æµ
    try {
        stream = await navigator.mediaDevices.getUserMedia({
            video: {
                facingMode: {exact: "user"}
            }
        })
        videoRef.value.srcObject = stream;
        await videoRef.value.play();
    } catch (err) {
        console.log(err)
    }
}

/*
è°ƒç”¨æ–¹æ³•è¿›è¡Œæµå¼è¯†åˆ«
 */
const flowRecognition = async () => {
    // è·å–æ‘„åƒå¤´å¹¶å»ºç«‹wsé“¾æ¥
    await getMediaStream()
    startWebSocket()
}
</script>

<style scoped>

</style>
